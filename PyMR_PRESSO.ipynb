{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install rdata\n"
      ],
      "metadata": {
        "id": "Ppmc0Ff_O6Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rdata\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "nJBQLw3KPEZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://github.com/rondolab/MR-PRESSO/raw/master/data/SummaryStats.rda # Changed to the raw URL for direct download.\n"
      ],
      "metadata": {
        "id": "C6W5zJkSlL0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted = rdata.read_rda(rdata.TESTDATA_PATH / \"/content/SummaryStats.rda\")"
      ],
      "metadata": {
        "id": "BE0YibEAPI1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'converted' already holds the data from 'rdata.read_rda'\n",
        "df = pd.DataFrame(converted['SummaryStats']) # Access the 'SummaryStats' key in the 'converted' dictionary\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RMTfazvGnIMx",
        "outputId": "8cbe3b66-5ed5-4c8b-c5a5-3bc9d805aa5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   E1_effect     E1_se       E1_pval  E2_effect     E2_se   E2_pval  Y_effect  \\\n",
              "1   2.050695  0.138190  8.315548e-27   0.160536  0.147190  0.278090  1.484821   \n",
              "2   2.034668  0.160594  2.312328e-22  -0.139266  0.145707  0.341528  0.857612   \n",
              "3   2.010319  0.143271  3.531301e-25   0.032016  0.146139  0.827046  1.147766   \n",
              "4   2.062171  0.147082  3.718466e-25  -0.122786  0.150158  0.415504  0.841744   \n",
              "5   2.114919  0.134503  1.506785e-28   0.003687  0.157837  0.981412  1.121555   \n",
              "\n",
              "       Y_se        Y_pval  \n",
              "1  0.174916  2.273003e-13  \n",
              "2  0.212624  1.088910e-04  \n",
              "3  0.194145  4.933370e-08  \n",
              "4  0.190183  2.494011e-05  \n",
              "5  0.172139  3.140024e-09  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8df5926d-32c5-474b-beed-c92840dba4e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>E1_effect</th>\n",
              "      <th>E1_se</th>\n",
              "      <th>E1_pval</th>\n",
              "      <th>E2_effect</th>\n",
              "      <th>E2_se</th>\n",
              "      <th>E2_pval</th>\n",
              "      <th>Y_effect</th>\n",
              "      <th>Y_se</th>\n",
              "      <th>Y_pval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.050695</td>\n",
              "      <td>0.138190</td>\n",
              "      <td>8.315548e-27</td>\n",
              "      <td>0.160536</td>\n",
              "      <td>0.147190</td>\n",
              "      <td>0.278090</td>\n",
              "      <td>1.484821</td>\n",
              "      <td>0.174916</td>\n",
              "      <td>2.273003e-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.034668</td>\n",
              "      <td>0.160594</td>\n",
              "      <td>2.312328e-22</td>\n",
              "      <td>-0.139266</td>\n",
              "      <td>0.145707</td>\n",
              "      <td>0.341528</td>\n",
              "      <td>0.857612</td>\n",
              "      <td>0.212624</td>\n",
              "      <td>1.088910e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.010319</td>\n",
              "      <td>0.143271</td>\n",
              "      <td>3.531301e-25</td>\n",
              "      <td>0.032016</td>\n",
              "      <td>0.146139</td>\n",
              "      <td>0.827046</td>\n",
              "      <td>1.147766</td>\n",
              "      <td>0.194145</td>\n",
              "      <td>4.933370e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.062171</td>\n",
              "      <td>0.147082</td>\n",
              "      <td>3.718466e-25</td>\n",
              "      <td>-0.122786</td>\n",
              "      <td>0.150158</td>\n",
              "      <td>0.415504</td>\n",
              "      <td>0.841744</td>\n",
              "      <td>0.190183</td>\n",
              "      <td>2.494011e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.114919</td>\n",
              "      <td>0.134503</td>\n",
              "      <td>1.506785e-28</td>\n",
              "      <td>0.003687</td>\n",
              "      <td>0.157837</td>\n",
              "      <td>0.981412</td>\n",
              "      <td>1.121555</td>\n",
              "      <td>0.172139</td>\n",
              "      <td>3.140024e-09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8df5926d-32c5-474b-beed-c92840dba4e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8df5926d-32c5-474b-beed-c92840dba4e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8df5926d-32c5-474b-beed-c92840dba4e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4abfdecf-128d-4c98-8cf2-042dfc536561\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4abfdecf-128d-4c98-8cf2-042dfc536561')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4abfdecf-128d-4c98-8cf2-042dfc536561 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"E1_effect\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13648266502717527,\n        \"min\": 1.6857126426292899,\n        \"max\": 2.2841761829003966,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          2.060400950395331,\n          2.239192710687497,\n          1.9687742065721245\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"E1_se\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01122694364086937,\n        \"min\": 0.12612185611058246,\n        \"max\": 0.1743798744486129,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.13010873041277818,\n          0.1743798744486129,\n          0.1489303523714997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"E1_pval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.315395940557917e-19,\n        \"min\": 1.258762218027396e-32,\n        \"max\": 1.6364707710902673e-18,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          9.126388809302191e-29,\n          1.0121371635592782e-22,\n          1.6475379916361678e-23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"E2_effect\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6378039274739987,\n        \"min\": -0.44469120820190916,\n        \"max\": 2.226696682164525,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          -0.040070109338056215,\n          -0.16494593039312383,\n          -0.10444005030804164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"E2_se\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012028202150115649,\n        \"min\": 0.11827709269070565,\n        \"max\": 0.17931513457770148,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.13117021814112453,\n          0.11827709269070565,\n          0.14058377931163496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"E2_pval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3275320954547784,\n        \"min\": 1.0935674415700806e-27,\n        \"max\": 0.9867856184586252,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.7606471763128264,\n          0.16629819116572106,\n          0.4593178153324513\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_effect\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26911229446256035,\n        \"min\": 0.7340435439182209,\n        \"max\": 1.9380939680674067,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.9555636039916706,\n          0.8516182579119842,\n          0.936769529670753\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_se\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01460614219299014,\n        \"min\": 0.14822313342925778,\n        \"max\": 0.21262353154405816,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.15526476600373076,\n          0.17936783899986444,\n          0.18139247704792805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_pval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3381470122962707e-05,\n        \"min\": 1.7507852048201486e-19,\n        \"max\": 0.00011900264370894736,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          1.6518101633143558e-08,\n          7.019557158383871e-06,\n          1.267825212596037e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/presso.csv')"
      ],
      "metadata": {
        "id": "_XrkdG2he7cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from scipy.linalg import eig, inv\n",
        "\n",
        "def mr_presso(BetaOutcome, BetaExposure, SdOutcome, SdExposure, data,\n",
        "              OUTLIERtest=False, DISTORTIONtest=False,\n",
        "              SignifThreshold=0.05, NbDistribution=1000, seed=None):\n",
        "\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    if SignifThreshold > 1:\n",
        "        raise ValueError(\"The significance threshold cannot be greater than 1\")\n",
        "\n",
        "    if len(BetaExposure) != len(SdExposure):\n",
        "        raise ValueError(\"BetaExposure and SdExposure must have the same number of elements\")\n",
        "\n",
        "    if not isinstance(data, pd.DataFrame):\n",
        "        raise TypeError(\"data must be a pandas DataFrame\")\n",
        "\n",
        "    # Helper function for matrix power using eigenvalue decomposition\n",
        "    def matrix_power(x, n):\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(x)\n",
        "        diag_power = np.diag(eigenvalues ** n)\n",
        "        inv_eigenvectors = np.linalg.inv(eigenvectors)\n",
        "        return eigenvectors @ diag_power @ inv_eigenvectors\n",
        "\n",
        "    # Function to compute the residual sum of squares using leave-one-out approach\n",
        "    def getRSS_LOO(BetaOutcome, BetaExposure, data, returnIV):\n",
        "        dataW = data[[BetaOutcome] + BetaExposure].apply(\n",
        "            lambda x: x * np.sqrt(data['Weights'])\n",
        "        )\n",
        "        X = dataW[BetaExposure].values\n",
        "        Y = dataW[BetaOutcome].values.reshape(-1, 1)\n",
        "        n = len(dataW)\n",
        "\n",
        "        CausalEstimate_LOO = []\n",
        "        for i in range(n):\n",
        "            X_loo = np.delete(X, i, axis=0)\n",
        "            Y_loo = np.delete(Y, i, axis=0)\n",
        "\n",
        "            XtX_inv = inv(X_loo.T @ X_loo)\n",
        "            beta_hat = XtX_inv @ X_loo.T @ Y_loo\n",
        "            CausalEstimate_LOO.append(beta_hat.flatten())\n",
        "\n",
        "        CausalEstimate_LOO = np.array(CausalEstimate_LOO)\n",
        "\n",
        "        if len(BetaExposure) == 1:\n",
        "            residuals = Y.flatten() - CausalEstimate_LOO.flatten() * X.flatten()\n",
        "            RSS = np.nansum(residuals ** 2)\n",
        "        else:\n",
        "            residuals = Y.flatten() - np.sum(CausalEstimate_LOO * X, axis=1)\n",
        "            RSS = np.nansum(residuals ** 2)\n",
        "\n",
        "        if returnIV:\n",
        "            return [RSS, CausalEstimate_LOO]\n",
        "        else:\n",
        "            return RSS\n",
        "\n",
        "    # Function to generate random data for simulations\n",
        "    def getRandomData(BetaOutcome, BetaExposure, SdOutcome, SdExposure, data):\n",
        "        n = len(data)\n",
        "        mod_IVW = []\n",
        "        for i in range(n):\n",
        "            data_loo = data.drop(data.index[i])\n",
        "            X_loo = data_loo[BetaExposure]\n",
        "            Y_loo = data_loo[BetaOutcome]\n",
        "            W_loo = data_loo['Weights']\n",
        "            model_loo = sm.WLS(Y_loo, X_loo, weights=W_loo)\n",
        "            results_loo = model_loo.fit()\n",
        "            mod_IVW.append(results_loo)\n",
        "\n",
        "        # Simulate exposures\n",
        "        random_exposures = pd.DataFrame()\n",
        "        for exp_var, sd_var in zip(BetaExposure, SdExposure):\n",
        "            random_exposures[exp_var] = np.random.normal(\n",
        "                loc=data[exp_var], scale=data[sd_var]\n",
        "            )\n",
        "\n",
        "        # Simulate outcomes\n",
        "        random_outcome = []\n",
        "        for i in range(n):\n",
        "            pred = mod_IVW[i].predict(data.iloc[i][BetaExposure])\n",
        "            sim_outcome = np.random.normal(\n",
        "                loc=pred, scale=data.iloc[i][SdOutcome]\n",
        "            )\n",
        "            random_outcome.append(sim_outcome)\n",
        "\n",
        "        random_data = pd.concat([random_exposures], axis=1)\n",
        "        random_data[BetaOutcome] = random_outcome\n",
        "        random_data['Weights'] = data['Weights'].values\n",
        "        return random_data\n",
        "\n",
        "    # Data preparation and validation\n",
        "    required_columns = [BetaOutcome] + BetaExposure + [SdOutcome] + SdExposure\n",
        "    data = data[required_columns].dropna()\n",
        "    data = data.reset_index(drop=True)\n",
        "\n",
        "    # Adjust signs based on the first exposure variable\n",
        "    sign_exposure = np.sign(data[BetaExposure[0]])\n",
        "    data[BetaOutcome] = data[BetaOutcome] * sign_exposure\n",
        "    for exp_var in BetaExposure:\n",
        "        data[exp_var] = data[exp_var] * sign_exposure\n",
        "\n",
        "    # Calculate weights\n",
        "    data['Weights'] = 1 / data[SdOutcome] ** 2\n",
        "\n",
        "    # Validate number of observations\n",
        "    if len(data) <= len(BetaExposure) + 2:\n",
        "        raise ValueError(\"Not enough instrumental variables\")\n",
        "\n",
        "    if len(data) >= NbDistribution:\n",
        "        raise ValueError(\"Not enough elements to compute empirical P-values, increase NbDistribution\")\n",
        "\n",
        "    # Step 1: Compute observed RSS\n",
        "    RSSobs = getRSS_LOO(BetaOutcome, BetaExposure, data, returnIV=OUTLIERtest)\n",
        "\n",
        "    # Step 2: Compute expected RSS distribution\n",
        "    randomData = [getRandomData(BetaOutcome, BetaExposure, SdOutcome, SdExposure, data)\n",
        "                  for _ in range(NbDistribution)]\n",
        "\n",
        "    RSSexp = []\n",
        "    for rd in randomData:\n",
        "        rss = getRSS_LOO(BetaOutcome, BetaExposure, rd, returnIV=OUTLIERtest)\n",
        "        if OUTLIERtest:\n",
        "            RSSexp.append(rss[0])\n",
        "        else:\n",
        "            RSSexp.append(rss)\n",
        "\n",
        "    RSSexp = np.array(RSSexp)\n",
        "\n",
        "    if OUTLIERtest:\n",
        "        GlobalTest = {\n",
        "            'RSSobs': RSSobs[0],\n",
        "            'Pvalue': np.sum(RSSexp > RSSobs[0]) / NbDistribution\n",
        "        }\n",
        "    else:\n",
        "        GlobalTest = {\n",
        "            'RSSobs': RSSobs,\n",
        "            'Pvalue': np.sum(RSSexp > RSSobs) / NbDistribution\n",
        "        }\n",
        "\n",
        "    # Step 3: Perform single IV outlier test\n",
        "    if GlobalTest['Pvalue'] < SignifThreshold and OUTLIERtest:\n",
        "        OutlierTest = []\n",
        "        n_snps = len(data)\n",
        "        for snv in range(n_snps):\n",
        "            randomSNP = pd.DataFrame([rd.iloc[snv] for rd in randomData])\n",
        "            if len(BetaExposure) == 1:\n",
        "                Dif = data.iloc[snv][BetaOutcome] - data.iloc[snv][BetaExposure] * RSSobs[1][snv]\n",
        "                Exp = randomSNP[BetaOutcome] - randomSNP[BetaExposure].values.flatten() * RSSobs[1][snv]\n",
        "            else:\n",
        "                Dif = data.iloc[snv][BetaOutcome] - np.sum(data.iloc[snv][BetaExposure].values * RSSobs[1][:, snv])\n",
        "                Exp = randomSNP[BetaOutcome] - np.sum(randomSNP[BetaExposure].values * RSSobs[1][:, snv], axis=1)\n",
        "            pval = np.sum(Exp ** 2 > Dif ** 2) / NbDistribution\n",
        "            OutlierTest.append({\n",
        "                'RSSobs': Dif ** 2,\n",
        "                'Pvalue': pval\n",
        "            })\n",
        "\n",
        "        OutlierTest = pd.DataFrame(OutlierTest)\n",
        "        OutlierTest.index = data.index\n",
        "\n",
        "        # Bonferroni correction\n",
        "        OutlierTest['Pvalue'] = np.minimum(OutlierTest['Pvalue'] * n_snps, 1)\n",
        "    else:\n",
        "        OUTLIERtest = False\n",
        "\n",
        "    # Step 4: Perform distortion test\n",
        "    X_all = data[BetaExposure]\n",
        "    Y_all = data[BetaOutcome]\n",
        "    W_all = data['Weights']\n",
        "    model_all = sm.WLS(Y_all, X_all, weights=W_all)\n",
        "    results_all = model_all.fit()\n",
        "\n",
        "    if DISTORTIONtest and OUTLIERtest:\n",
        "        refOutlier = OutlierTest[OutlierTest['Pvalue'] <= SignifThreshold].index.tolist()\n",
        "\n",
        "        if len(refOutlier) > 0:\n",
        "            if len(refOutlier) < len(data):\n",
        "                def getRandomBias(BetaOutcome, BetaExposure, data, refOutlier):\n",
        "                    n = len(data)\n",
        "                    indices = refOutlier + list(\n",
        "                        np.random.choice(\n",
        "                            data.index.difference(refOutlier),\n",
        "                            size=n - len(refOutlier),\n",
        "                            replace=False\n",
        "                        )\n",
        "                    )\n",
        "                    data_subset = data.loc[indices[:n - len(refOutlier)]]\n",
        "                    X_subset = data_subset[BetaExposure]\n",
        "                    Y_subset = data_subset[BetaOutcome]\n",
        "                    W_subset = data_subset['Weights']\n",
        "                    model_random = sm.WLS(Y_subset, X_subset, weights=W_subset)\n",
        "                    results_random = model_random.fit()\n",
        "                    return results_random.params\n",
        "\n",
        "                BiasExp = []\n",
        "                for _ in range(NbDistribution):\n",
        "                    bias = getRandomBias(BetaOutcome, BetaExposure, data, refOutlier)\n",
        "                    BiasExp.append(bias)\n",
        "                BiasExp = pd.DataFrame(BiasExp)\n",
        "\n",
        "                data_no_outliers = data.drop(refOutlier)\n",
        "                X_no_outliers = data_no_outliers[BetaExposure]\n",
        "                Y_no_outliers = data_no_outliers[BetaOutcome]\n",
        "                W_no_outliers = data_no_outliers['Weights']\n",
        "                model_no_outliers = sm.WLS(Y_no_outliers, X_no_outliers, weights=W_no_outliers)\n",
        "                results_no_outliers = model_no_outliers.fit()\n",
        "\n",
        "                BiasObs = (results_all.params - results_no_outliers.params) / np.abs(results_no_outliers.params)\n",
        "                BiasExp = (results_all.params.values.reshape(1, -1) - BiasExp) / np.abs(BiasExp)\n",
        "\n",
        "                pvalues = []\n",
        "                for idx in range(len(BetaExposure)):\n",
        "                    pvalue = np.sum(np.abs(BiasExp.iloc[:, idx]) > np.abs(BiasObs[idx])) / NbDistribution\n",
        "                    pvalues.append(pvalue)\n",
        "\n",
        "                BiasTest = {\n",
        "                    'Outliers Indices': refOutlier,\n",
        "                    'Distortion Coefficient (%)': 100 * BiasObs,\n",
        "                    'Pvalue': pvalues\n",
        "                }\n",
        "            else:\n",
        "                BiasTest = {\n",
        "                    'Outliers Indices': \"All SNPs considered as outliers\",\n",
        "                    'Distortion Coefficient (%)': None,\n",
        "                    'Pvalue': None\n",
        "                }\n",
        "        else:\n",
        "            BiasTest = {\n",
        "                'Outliers Indices': \"No significant outliers\",\n",
        "                'Distortion Coefficient (%)': None,\n",
        "                'Pvalue': None\n",
        "            }\n",
        "    else:\n",
        "        DISTORTIONtest = False\n",
        "\n",
        "    # Step 5: Formatting the results\n",
        "    if GlobalTest['Pvalue'] == 0:\n",
        "        GlobalTest['Pvalue'] = f\"<{1 / NbDistribution}\"\n",
        "\n",
        "    results = {\n",
        "        'Global Test': GlobalTest\n",
        "    }\n",
        "\n",
        "    if OUTLIERtest:\n",
        "        OutlierTest['Pvalue'] = OutlierTest['Pvalue'].apply(lambda x: f\"<{1 / NbDistribution}\" if x == 0 else x)\n",
        "        results['Outlier Test'] = OutlierTest\n",
        "\n",
        "        if DISTORTIONtest:\n",
        "            BiasTest['Pvalue'] = [f\"<{1 / NbDistribution}\" if p == 0 else p for p in BiasTest['Pvalue']]\n",
        "            results['Distortion Test'] = BiasTest\n",
        "\n",
        "    # Main MR results\n",
        "    MR_results = pd.DataFrame({\n",
        "        'Exposure': BetaExposure,\n",
        "        'MR Analysis': 'Raw',\n",
        "        'Causal Estimate': results_all.params.values,\n",
        "        'Std Error': results_all.bse.values,\n",
        "        'T-stat': results_all.tvalues,\n",
        "        'P-value': results_all.pvalues\n",
        "    })\n",
        "\n",
        "    if DISTORTIONtest and 'Outliers Indices' in BiasTest and isinstance(BiasTest['Outliers Indices'], list):\n",
        "        data_no_outliers = data.drop(BiasTest['Outliers Indices'])\n",
        "        X_no_outliers = data_no_outliers[BetaExposure]\n",
        "        Y_no_outliers = data_no_outliers[BetaOutcome]\n",
        "        W_no_outliers = data_no_outliers['Weights']\n",
        "        model_no_outliers = sm.WLS(Y_no_outliers, X_no_outliers, weights=W_no_outliers)\n",
        "        results_no_outliers = model_no_outliers.fit()\n",
        "\n",
        "        MR_results_no_outliers = pd.DataFrame({\n",
        "            'Exposure': BetaExposure,\n",
        "            'MR Analysis': 'Outlier-corrected',\n",
        "            'Causal Estimate': results_no_outliers.params.values,\n",
        "            'Std Error': results_no_outliers.bse.values,\n",
        "            'T-stat': results_no_outliers.tvalues,\n",
        "            'P-value': results_no_outliers.pvalues\n",
        "        })\n",
        "    else:\n",
        "        MR_results_no_outliers = pd.DataFrame({\n",
        "            'Exposure': BetaExposure,\n",
        "            'MR Analysis': 'Outlier-corrected',\n",
        "            'Causal Estimate': [np.nan] * len(BetaExposure),\n",
        "            'Std Error': [np.nan] * len(BetaExposure),\n",
        "            'T-stat': [np.nan] * len(BetaExposure),\n",
        "            'P-value': [np.nan] * len(BetaExposure)\n",
        "        })\n",
        "\n",
        "    MR_main_results = pd.concat([MR_results, MR_results_no_outliers], ignore_index=True)\n",
        "    results['Main MR results'] = MR_main_results\n",
        "\n",
        "    # Warning if necessary\n",
        "    if OUTLIERtest and (len(data) / NbDistribution > SignifThreshold):\n",
        "        print(f\"Warning: Outlier test unstable. The significance threshold of {SignifThreshold} for the outlier test \"\n",
        "              f\"is not achievable with only {NbDistribution} simulations to compute the null distribution. \"\n",
        "              f\"The current precision is <{len(data) / NbDistribution}. Increase NbDistribution.\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "9oPuK-yk70j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BetaOutcome = 'Y_effect'\n",
        "BetaExposure = ['E1_effect', 'E2_effect']\n",
        "SdOutcome = 'Y_se'\n",
        "SdExposure = ['E1_se', 'E2_se']"
      ],
      "metadata": {
        "id": "kjZbWq7O8QbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#single variable MR_PRESSO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "def mr_presso_single_optimized(BetaOutcome, BetaExposure, SdOutcome, SdExposure, data,\n",
        "                               OUTLIERtest=False, DISTORTIONtest=False,\n",
        "                               SignifThreshold=0.05, NbDistribution=1000, seed=None, n_jobs=-1):\n",
        "    \"\"\"\n",
        "    Optimized version of MR-PRESSO analysis for a single exposure and outcome.\n",
        "    \"\"\"\n",
        "\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    if SignifThreshold > 1 or SignifThreshold < 0:\n",
        "        raise ValueError(\"The significance threshold must be between 0 and 1\")\n",
        "\n",
        "    if not isinstance(data, pd.DataFrame):\n",
        "        raise TypeError(\"data must be a pandas DataFrame\")\n",
        "\n",
        "    # Ensure that inputs are in the correct format\n",
        "    if isinstance(BetaExposure, str):\n",
        "        BetaExposure = [BetaExposure]\n",
        "    if isinstance(SdExposure, str):\n",
        "        SdExposure = [SdExposure]\n",
        "\n",
        "    if len(BetaExposure) != len(SdExposure):\n",
        "        raise ValueError(\"BetaExposure and SdExposure must have the same number of elements\")\n",
        "\n",
        "    # Data preparation and validation\n",
        "    required_columns = [BetaOutcome] + BetaExposure + [SdOutcome] + SdExposure\n",
        "    data = data[required_columns].dropna()\n",
        "    data = data.reset_index(drop=True)  # Reset index to ensure alignment\n",
        "    n_snps = len(data)\n",
        "\n",
        "    # Adjust signs based on the first exposure variable\n",
        "    sign_exposure = np.sign(data[BetaExposure[0]].values)\n",
        "    data[BetaOutcome] *= sign_exposure\n",
        "    data[BetaExposure[0]] *= sign_exposure\n",
        "\n",
        "    # Calculate weights\n",
        "    data['Weights'] = 1 / data[SdOutcome].values ** 2\n",
        "\n",
        "    # Validate number of observations\n",
        "    if len(data) <= len(BetaExposure) + 2:\n",
        "        raise ValueError(\"Not enough instrumental variables\")\n",
        "\n",
        "    if len(data) >= NbDistribution:\n",
        "        raise ValueError(\"Not enough elements to compute empirical P-values; increase NbDistribution\")\n",
        "\n",
        "    # Precompute variables for efficiency\n",
        "    sqrt_weights = np.sqrt(data['Weights'].values)\n",
        "    dataW = data[[BetaOutcome] + BetaExposure].multiply(sqrt_weights[:, np.newaxis], axis=0)\n",
        "    X = dataW[BetaExposure].values\n",
        "    Y = dataW[BetaOutcome].values\n",
        "    n = len(dataW)\n",
        "\n",
        "    # Function to compute the residual sum of squares using leave-one-out approach\n",
        "    def getRSS_LOO(X, Y):\n",
        "        XtX = X.T @ X\n",
        "        XtY = X.T @ Y\n",
        "        XtX_inv = np.linalg.inv(XtX)\n",
        "        beta_hat_full = XtX_inv @ XtY\n",
        "        residuals_full = Y - X @ beta_hat_full\n",
        "        RSS_full = np.sum(residuals_full ** 2)\n",
        "\n",
        "        if OUTLIERtest:\n",
        "            # Precompute leave-one-out estimates\n",
        "            CausalEstimate_LOO = np.zeros(n)\n",
        "            residuals_LOO = np.zeros(n)\n",
        "            for i in range(n):\n",
        "                X_loo = np.delete(X, i, axis=0)\n",
        "                Y_loo = np.delete(Y, i)\n",
        "                XtX_loo = X_loo.T @ X_loo\n",
        "                XtY_loo = X_loo.T @ Y_loo\n",
        "                beta_hat_loo = np.linalg.inv(XtX_loo) @ XtY_loo\n",
        "                CausalEstimate_LOO[i] = beta_hat_loo[0]\n",
        "                residuals_LOO[i] = Y[i] - X[i] @ beta_hat_loo\n",
        "            RSS = np.sum(residuals_LOO ** 2)\n",
        "            return RSS, CausalEstimate_LOO\n",
        "        else:\n",
        "            return RSS_full\n",
        "\n",
        "    # Function to generate random data for simulations\n",
        "    def getRandomData(data_np):\n",
        "        n = len(data_np['BetaOutcome'])\n",
        "        # Simulate exposures\n",
        "        random_exposures = np.random.normal(\n",
        "            loc=data_np['BetaExposure'], scale=data_np['SdExposure']\n",
        "        )\n",
        "        # Simulate outcomes\n",
        "        pred_outcomes = random_exposures * data_np['IVW_estimates']\n",
        "        random_outcome = np.random.normal(\n",
        "            loc=pred_outcomes, scale=data_np['SdOutcome']\n",
        "        )\n",
        "        random_data = {\n",
        "            'BetaOutcome': random_outcome,\n",
        "            'BetaExposure': random_exposures,\n",
        "            'Weights': data_np['Weights']\n",
        "        }\n",
        "        random_data = pd.DataFrame(random_data)\n",
        "        return random_data\n",
        "\n",
        "    # Precompute IVW estimates for leave-one-out\n",
        "    if OUTLIERtest:\n",
        "        IVW_estimates = np.zeros(n)\n",
        "        for i in range(n):\n",
        "            indices = np.arange(n) != i\n",
        "            X_loo = X[indices]\n",
        "            Y_loo = Y[indices]\n",
        "            XtX_loo = X_loo.T @ X_loo\n",
        "            XtY_loo = X_loo.T @ Y_loo\n",
        "            beta_hat_loo = np.linalg.inv(XtX_loo) @ XtY_loo\n",
        "            IVW_estimates[i] = beta_hat_loo[0]\n",
        "        data_np = {\n",
        "            'BetaOutcome': data[BetaOutcome].values,\n",
        "            'BetaExposure': data[BetaExposure[0]].values,\n",
        "            'SdOutcome': data[SdOutcome].values,\n",
        "            'SdExposure': data[SdExposure[0]].values,\n",
        "            'Weights': data['Weights'].values,\n",
        "            'IVW_estimates': IVW_estimates\n",
        "        }\n",
        "    else:\n",
        "        # Compute full IVW estimate\n",
        "        XtX = X.T @ X\n",
        "        XtY = X.T @ Y\n",
        "        beta_hat_full = np.linalg.inv(XtX) @ XtY\n",
        "        data_np = {\n",
        "            'BetaOutcome': data[BetaOutcome].values,\n",
        "            'BetaExposure': data[BetaExposure[0]].values,\n",
        "            'SdOutcome': data[SdOutcome].values,\n",
        "            'SdExposure': data[SdExposure[0]].values,\n",
        "            'Weights': data['Weights'].values,\n",
        "            'IVW_estimates': np.full(n, beta_hat_full[0])\n",
        "        }\n",
        "\n",
        "    # Step 1: Compute observed RSS\n",
        "    RSSobs = getRSS_LOO(X, Y)\n",
        "\n",
        "    # Step 2: Compute expected RSS distribution (Parallelized)\n",
        "    random_data_list = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(getRandomData)(data_np) for _ in range(NbDistribution)\n",
        "    )\n",
        "\n",
        "    # Function to process each random dataset\n",
        "    def process_random_data(random_data):\n",
        "        # Recompute weights for the random data\n",
        "        sqrt_weights_random = np.sqrt(random_data['Weights'].values)\n",
        "        X_random = random_data[['BetaExposure']].values * sqrt_weights_random[:, np.newaxis]\n",
        "        Y_random = random_data['BetaOutcome'].values * sqrt_weights_random\n",
        "        return getRSS_LOO(X_random, Y_random)\n",
        "\n",
        "    RSSexp_list = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(process_random_data)(random_data) for random_data in random_data_list\n",
        "    )\n",
        "\n",
        "    # Extract RSS values from RSSexp_list\n",
        "    if OUTLIERtest:\n",
        "        RSSexp = np.array([rss[0] for rss in RSSexp_list])\n",
        "    else:\n",
        "        RSSexp = np.array(RSSexp_list)\n",
        "\n",
        "    RSSobs_value = RSSobs[0] if OUTLIERtest else RSSobs\n",
        "    GlobalTest_Pvalue = np.mean(RSSexp > RSSobs_value)\n",
        "    if GlobalTest_Pvalue == 0:\n",
        "        GlobalTest_Pvalue = f\"<{1 / NbDistribution}\"\n",
        "\n",
        "    GlobalTest = {\n",
        "        'RSSobs': RSSobs_value,\n",
        "        'Pvalue': GlobalTest_Pvalue\n",
        "    }\n",
        "\n",
        "    # Step 3: Perform single IV outlier test\n",
        "    if ((float(str(GlobalTest['Pvalue']).lstrip('<')) if isinstance(GlobalTest['Pvalue'], str) else GlobalTest['Pvalue'])\n",
        "        < SignifThreshold) and OUTLIERtest:\n",
        "        # Vectorized calculation for outlier test\n",
        "        CausalEstimate_LOO = RSSobs[1]\n",
        "        Dif = data[BetaOutcome].values - data[BetaExposure[0]].values * CausalEstimate_LOO\n",
        "        RSSobs_squared = Dif ** 2\n",
        "\n",
        "        Exp_diff = np.empty((NbDistribution, n_snps))\n",
        "        for i, rd in enumerate(random_data_list):\n",
        "            # Recompute weights for each random dataset\n",
        "            sqrt_weights_random = np.sqrt(rd['Weights'].values)\n",
        "            X_random = rd[['BetaExposure']].values * sqrt_weights_random[:, np.newaxis]\n",
        "            Y_random = rd['BetaOutcome'].values * sqrt_weights_random\n",
        "            _, CausalEstimate_LOO_random = getRSS_LOO(X_random, Y_random)\n",
        "            Exp_diff[i] = rd['BetaOutcome'].values - rd['BetaExposure'].values * CausalEstimate_LOO_random\n",
        "\n",
        "        Pvalues = np.mean(Exp_diff ** 2 > RSSobs_squared[None, :], axis=0)\n",
        "        Pvalues_corrected = np.minimum(Pvalues * n_snps, 1)\n",
        "        Pvalues_corrected = np.where(Pvalues_corrected == 0, f\"<{1 / NbDistribution}\", Pvalues_corrected)\n",
        "\n",
        "        OutlierTest = pd.DataFrame({\n",
        "            'SNP': data.index,\n",
        "            'RSSobs': RSSobs_squared,\n",
        "            'Pvalue': Pvalues_corrected\n",
        "        })\n",
        "    else:\n",
        "        OUTLIERtest = False\n",
        "        OutlierTest = pd.DataFrame()\n",
        "\n",
        "    # Step 4: Perform distortion test\n",
        "    X_all = data[BetaExposure].values\n",
        "    Y_all = data[BetaOutcome].values\n",
        "    W_all = data['Weights'].values\n",
        "    model_all = sm.WLS(Y_all, X_all, weights=W_all)\n",
        "    results_all = model_all.fit()\n",
        "\n",
        "    BiasTest = {}\n",
        "    if DISTORTIONtest and OUTLIERtest:\n",
        "        significant_mask = OutlierTest['Pvalue'].apply(\n",
        "            lambda x: float(x) if isinstance(x, str) and not x.startswith('<') else 0.0\n",
        "        ).astype(float) <= SignifThreshold\n",
        "        refOutlier = OutlierTest.loc[significant_mask, 'SNP'].tolist()\n",
        "\n",
        "        if len(refOutlier) > 0 and len(refOutlier) < len(data):\n",
        "            # Function to get random distortion coefficients\n",
        "            def getRandomBias(refOutlier_indices):\n",
        "                indices_remaining = list(set(range(n_snps)) - set(refOutlier_indices))\n",
        "                random_indices = refOutlier_indices + list(\n",
        "                    np.random.choice(indices_remaining, size=n_snps - len(refOutlier_indices), replace=False)\n",
        "                )\n",
        "                data_subset = data.iloc[random_indices]\n",
        "                X_subset = data_subset[BetaExposure].values\n",
        "                Y_subset = data_subset[BetaOutcome].values\n",
        "                W_subset = data_subset['Weights'].values\n",
        "                model_random = sm.WLS(Y_subset, X_subset, weights=W_subset)\n",
        "                results_random = model_random.fit()\n",
        "                return results_random.params[0]\n",
        "\n",
        "            BiasExp = Parallel(n_jobs=n_jobs)(\n",
        "                delayed(getRandomBias)(refOutlier) for _ in range(NbDistribution)\n",
        "            )\n",
        "            BiasExp = np.array(BiasExp)\n",
        "\n",
        "            data_no_outliers = data.drop(index=refOutlier).reset_index(drop=True)\n",
        "            X_no_outliers = data_no_outliers[BetaExposure].values\n",
        "            Y_no_outliers = data_no_outliers[BetaOutcome].values\n",
        "            W_no_outliers = data_no_outliers['Weights'].values\n",
        "            model_no_outliers = sm.WLS(Y_no_outliers, X_no_outliers, weights=W_no_outliers)\n",
        "            results_no_outliers = model_no_outliers.fit()\n",
        "\n",
        "            BiasObs = (results_all.params[0] - results_no_outliers.params[0]) / np.abs(results_no_outliers.params[0])\n",
        "            BiasExp = (results_all.params[0] - BiasExp) / np.abs(BiasExp)\n",
        "\n",
        "            BiasTest_Pvalue = np.mean(np.abs(BiasExp) > np.abs(BiasObs))\n",
        "            if BiasTest_Pvalue == 0:\n",
        "                BiasTest_Pvalue = f\"<{1 / NbDistribution}\"\n",
        "\n",
        "            BiasTest = {\n",
        "                'Outliers Indices': refOutlier,\n",
        "                'Distortion Coefficient (%)': 100 * BiasObs,\n",
        "                'Pvalue': BiasTest_Pvalue\n",
        "            }\n",
        "        else:\n",
        "            BiasTest = {\n",
        "                'Outliers Indices': \"All SNPs considered as outliers or no significant outliers\",\n",
        "                'Distortion Coefficient (%)': None,\n",
        "                'Pvalue': None\n",
        "            }\n",
        "\n",
        "    # Step 5: Formatting results\n",
        "    results = {\n",
        "        'Global Test': GlobalTest\n",
        "    }\n",
        "\n",
        "    if OUTLIERtest:\n",
        "        results['Outlier Test'] = OutlierTest\n",
        "\n",
        "        if DISTORTIONtest:\n",
        "            results['Distortion Test'] = BiasTest\n",
        "\n",
        "    # Main MR results\n",
        "    MR_results_list = []\n",
        "\n",
        "    # Original MR\n",
        "    MR_results_list.append({\n",
        "        'Exposure': BetaExposure[0],\n",
        "        'MR Analysis': 'Raw',\n",
        "        'Causal Estimate': results_all.params[0],\n",
        "        'Sd': results_all.bse[0],\n",
        "        'T-stat': results_all.tvalues[0],\n",
        "        'P-value': results_all.pvalues[0]\n",
        "    })\n",
        "\n",
        "    # Outlier-corrected MR\n",
        "    if DISTORTIONtest and 'Outliers Indices' in BiasTest and \\\n",
        "            isinstance(BiasTest['Outliers Indices'], list) and len(BiasTest['Outliers Indices']) < len(data):\n",
        "        data_no_outliers = data.drop(index=BiasTest['Outliers Indices']).reset_index(drop=True)\n",
        "        X_no_outliers = data_no_outliers[BetaExposure].values\n",
        "        Y_no_outliers = data_no_outliers[BetaOutcome].values\n",
        "        W_no_outliers = data_no_outliers['Weights'].values\n",
        "        model_no_outliers = sm.WLS(Y_no_outliers, X_no_outliers, weights=W_no_outliers)\n",
        "        results_no_outliers = model_no_outliers.fit()\n",
        "\n",
        "        MR_results_list.append({\n",
        "            'Exposure': BetaExposure[0],\n",
        "            'MR Analysis': 'Outlier-corrected',\n",
        "            'Causal Estimate': results_no_outliers.params[0],\n",
        "            'Sd': results_no_outliers.bse[0],\n",
        "            'T-stat': results_no_outliers.tvalues[0],\n",
        "            'P-value': results_no_outliers.pvalues[0]\n",
        "        })\n",
        "    else:\n",
        "        MR_results_list.append({\n",
        "            'Exposure': BetaExposure[0],\n",
        "            'MR Analysis': 'Outlier-corrected',\n",
        "            'Causal Estimate': np.nan,\n",
        "            'Sd': np.nan,\n",
        "            'T-stat': np.nan,\n",
        "            'P-value': np.nan\n",
        "        })\n",
        "\n",
        "    MR_results = pd.DataFrame(MR_results_list)\n",
        "    results['Main MR results'] = MR_results\n",
        "\n",
        "    # Warning if necessary\n",
        "    if OUTLIERtest and (len(data) / NbDistribution > SignifThreshold):\n",
        "        print(f\"Warning: Outlier test unstable. The significance threshold of {SignifThreshold} for the outlier test \"\n",
        "              f\"is not achievable with only {NbDistribution} simulations to compute the null distribution. \"\n",
        "              f\"The current precision is <{len(data) / NbDistribution}. Increase NbDistribution.\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "ia3q7PXyErlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Assuming you have a DataFrame 'data' with the necessary columns\n",
        "results = mr_presso_single_optimized(\n",
        "    BetaOutcome='Y_effect',\n",
        "    BetaExposure='E1_effect',\n",
        "    SdOutcome='Y_se',\n",
        "    SdExposure='E1_se',\n",
        "    data=df2,\n",
        "    OUTLIERtest=True,\n",
        "    DISTORTIONtest=True,  # Enable the DISTORTIONtest\n",
        "    SignifThreshold=0.05,\n",
        "    NbDistribution=8000,\n",
        "    seed=80\n",
        ")\n",
        "results"
      ],
      "metadata": {
        "id": "zoe5h7EeQL6e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}